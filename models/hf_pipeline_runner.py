"""
ğŸ“¦ Model Adapter: hf_pipeline_runner
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- HuggingFaceì˜ transformers.pipelineì„ ê¸°ë°˜ìœ¼ë¡œ ë™ì‘
- ë‹¤ì–‘í•œ íƒœìŠ¤í¬(sentiment-analysis, ner, translation ë“±)ì— ëŒ€ì‘ ê°€ëŠ¥
- ëª¨ë¸ ì´ë¦„ê³¼ íƒœìŠ¤í¬ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ ë™ì ìœ¼ë¡œ pipeline ìƒì„±
- ì‹¤í–‰ ì†ë„ë¥¼ ìœ„í•´ ìºì‹± êµ¬ì¡°(_cached_models) ì‚¬ìš©

ğŸ“Œ ì…ë ¥ ì˜ˆì‹œ:
{
    "text": "ì˜¤ëŠ˜ ê¸°ë¶„ ì¢‹ì•„ìš”"
}

ğŸ“Œ íŒŒë¼ë¯¸í„° ì˜ˆì‹œ:
task="sentiment-analysis", model_name="beomi/kcbert-base"
"""

from transformers import pipeline

# âœ… ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìºì‹± (task:ëª¨ë¸ëª… ê¸°ì¤€)
_cached_models = {}

# ---------------------------------------------------
# ğŸ“Œ ëª¨ë¸ ì‹¤í–‰ í•¨ìˆ˜
# - ì…ë ¥ ë°ì´í„°ë¥¼ ë°›ì•„ ì§€ì •í•œ taskë¡œ ì¶”ë¡  ìˆ˜í–‰
# - ë™ì¼ task/model ì¡°í•©ì€ ìºì‹œ ì¬ì‚¬ìš©
# ---------------------------------------------------
def run(
    input: dict,
    task: str = "sentiment-analysis",
    model_name: str = None,
    reload: bool = False,
    **kwargs
):
    """
    HuggingFace pipeline ì‹¤í–‰ê¸°

    âœ… ì¸ì:
    - input: {"text": ...} ë˜ëŠ” ê¸°íƒ€ dict ì…ë ¥
    - task: ê°ì„± ë¶„ì„, ë²ˆì—­, ìš”ì•½ ë“± pipeline íƒœìŠ¤í¬
    - model_name: ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„ (ì˜ˆ: beomi/kcbert-base)
    - reload: Trueì¼ ê²½ìš° ê¸°ì¡´ ìºì‹œ ë¬´ì‹œí•˜ê³  ì¬ë¡œë”©
    """

    # âœ… ëª¨ë¸ ìºì‹± í‚¤ ìƒì„±: ì˜ˆ) "sentiment-analysis:beomi/kcbert-base"
    key = f"{task}:{model_name or 'default'}"

    # ğŸ”„ ìºì‹œê°€ ì—†ê±°ë‚˜ reload ìš”ì²­ ì‹œ ìƒˆë¡œ ë¡œë”©
    if reload or key not in _cached_models:
        _cached_models[key] = pipeline(task, model=model_name)

    pipe = _cached_models[key]

    # ---------------------------------------------------
    # âœ… íƒœìŠ¤í¬ ìœ í˜•ë³„ ì…ë ¥ ì²˜ë¦¬
    # ---------------------------------------------------

    if task in ["sentiment-analysis", "ner", "zero-shot-classification"]:
        # âœ… ì´ íƒœìŠ¤í¬ë“¤ì€ ë¬¸ìì—´(text) ë˜ëŠ” ë‹¨ìˆœ dict ì…ë ¥ì„ ê¸°ëŒ€
        text = input.get("text", "")
        return pipe(text)

    elif task in ["translation", "summarization", "text2text-generation"]:
        # âœ… ì´ íƒœìŠ¤í¬ë“¤ì€ dict ë˜ëŠ” í…ìŠ¤íŠ¸ ì‹œí€€ìŠ¤ë¥¼ ê¸°ëŒ€
        return pipe(input)

    else:
        # ğŸš¨ ì •ì˜ë˜ì§€ ì•Šì€ íƒœìŠ¤í¬: fallback ì²˜ë¦¬
        return pipe(str(input))