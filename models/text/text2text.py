"""
ğŸ“¦ Text2Text Generation ì‹¤í–‰ê¸°
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- text2text-generation íƒœìŠ¤í¬ ì‹¤í–‰
- ì…ë ¥ í…ìŠ¤íŠ¸ì— ëŒ€í•´ ë‹¤ì–‘í•œ ëª©ì ì˜ í…ìŠ¤íŠ¸ ìƒì„± (T5, FLAN-T5, BART ë“±)
- model_name ì§€ì • ê°€ëŠ¥, ìºì‹± ì²˜ë¦¬ í¬í•¨
"""

from transformers import pipeline

_cached_models = {}

def run(input, model_name=None, reload=False, **kwargs):
    # ğŸ“Œ run(): text2text-generation íƒœìŠ¤í¬ìš© pipeline ì‹¤í–‰ (ìºì‹œ í¬í•¨)
    key = f"text2text-generation:{model_name or 'default'}"

    # âœ… ëª¨ë¸ ìºì‹± ë˜ëŠ” ê°•ì œ ì¬ë¡œë”© ì²˜ë¦¬
    if reload or key not in _cached_models:
        _cached_models[key] = pipeline("text2text-generation", model=model_name)

    pipe = _cached_models[key]

    # ğŸ“¤ ìƒì„± ì‹¤í–‰ (ì˜ˆ: ë²ˆì—­, ìš”ì•½, QA ë“± í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ì²˜ë¦¬ ê°€ëŠ¥)
    return pipe(input["text"], **kwargs)