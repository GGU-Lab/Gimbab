"""
ğŸ“¦ Text Generation ì‹¤í–‰ê¸°
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- text-generation íƒœìŠ¤í¬ ì‹¤í–‰ (ì˜ˆ: GPT2, GPT-J ë“±)
- ììœ  ìƒì„±(generative) ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ í›„ì† í…ìŠ¤íŠ¸ ìƒì„±
- model_name ì§€ì • ê°€ëŠ¥, ìºì‹± ì²˜ë¦¬ í¬í•¨
"""

from transformers import pipeline

_cached_models = {}

def run(input, model_name=None, reload=False, **kwargs):
    # ğŸ“Œ run(): í…ìŠ¤íŠ¸ ìƒì„± íƒœìŠ¤í¬ìš© pipeline ì‹¤í–‰ (ìºì‹œ í¬í•¨)
    key = f"text-generation:{model_name or 'default'}"

    # âœ… ëª¨ë¸ ìºì‹± ë˜ëŠ” ê°•ì œ ì¬ë¡œë”© ì²˜ë¦¬
    if reload or key not in _cached_models:
        _cached_models[key] = pipeline("text-generation", model=model_name)

    pipe = _cached_models[key]

    # ğŸ“¤ ìƒì„± ì‹¤í–‰ (max_new_tokens ë“±ì€ kwargsë¡œ ì œì–´)
    return pipe(input["text"], **kwargs)
