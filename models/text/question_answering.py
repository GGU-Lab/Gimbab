"""
ğŸ“¦ Question Answering ì‹¤í–‰ê¸°
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- question-answering íƒœìŠ¤í¬ ì‹¤í–‰
- ì£¼ì–´ì§„ ì§ˆë¬¸ê³¼ ë¬¸ë§¥(context)ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ì¶”ì¶œ
- model_name ì§€ì • ê°€ëŠ¥, ìºì‹± ë° ë¡œê¹… ì²˜ë¦¬ í¬í•¨
"""

from transformers import pipeline

_cached_models = {}

def run(input, model_name=None, reload=False):
    # ğŸ“Œ run(): question-answering íƒœìŠ¤í¬ìš© pipeline ì‹¤í–‰ (ìºì‹œ ë° ê²€ì¦ í¬í•¨)
    key = f"question-answering:{model_name or 'default'}"

    # âœ… ëª¨ë¸ ìºì‹± ë˜ëŠ” ê°•ì œ ì¬ë¡œë”© ì²˜ë¦¬
    if reload or key not in _cached_models:
        print(f"[LOAD MODEL] task=question-answering | model={model_name}")
        _cached_models[key] = pipeline("question-answering", model=model_name)

    pipe = _cached_models[key]

    # âœ… ì…ë ¥ ë¡œê·¸ ì¶œë ¥ (ë””ë²„ê¹… ìš©ë„)
    print(f"[RUN] Received input: {input}")
    print(f"[RUN] model_name: {model_name}")

    # ğŸš« ì…ë ¥ íƒ€ì… í™•ì¸: dictê°€ ì•„ë‹ ê²½ìš° ì˜ˆì™¸ ì²˜ë¦¬
    if not isinstance(input, dict):
        print(f"[ERROR] Input is not a dict! Type: {type(input)}")
        raise TypeError(f"âŒ Invalid input type for QA task: {type(input)}. Expected dict.")

    # ğŸ§¾ ì§ˆë¬¸ ë° ë¬¸ë§¥ ì¶”ì¶œ
    question = input.get("question")
    context = input.get("context")

    # ğŸš« í•„ìˆ˜ í•­ëª© ëˆ„ë½ ê²€ì‚¬
    if not question or not context:
        print(f"[ERROR] Missing question/context | question={question} | context={context}")
        raise ValueError("âŒ question-answering requires both 'question' and 'context'.")

    # âœ… ì‹¤í–‰ ë¡œê·¸: ì‹¤ì œ ì‹¤í–‰ë˜ëŠ” ì§ˆì˜ ì •ë³´ í‘œì‹œ
    print(f"[EXECUTE] QA: {question} / {len(context)} chars context")

    # ğŸ“¤ ì§ˆì˜ì‘ë‹µ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    return pipe({ "question": question, "context": context })